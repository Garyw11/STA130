{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fefb8948",
   "metadata": {},
   "source": [
    "# Homework Week 10\n",
    "\n",
    "#### ChatGPT history logs:\n",
    "\n",
    "Q1, 2: https://chatgpt.com/share/672bd608-9660-8004-8c06-3b834dbb6ad8\n",
    "\n",
    "Q3: https://chatgpt.com/share/672c0b79-5c98-8004-ab90-f72b494dd944\n",
    "\n",
    "Q4, 5, 6, 7, 8: https://chatgpt.com/share/672c26bd-5d68-8004-850c-4718619d5f61\n",
    "\n",
    "Q9: https://chatgpt.com/share/672c26a9-c0a0-8004-abd5-e24da67c3909"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845e2fe",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "1. Simple Linear Regression uses only one predictor to predict the outcome while Multiple Linear Regression invovles two or more predictors. MLR provides better accuracy for complex relationships, but it also requires more data and potential correlation of the predictors.\n",
    "\n",
    "2. A continuous variable captures the linear or proportional change within the outcome and the indicator variable captures a categorical effect, representing the difference.\n",
    "\n",
    "3. Adding this indicator variable allows the model to have two parrallel lines with different intercepts but same slopes across both groups. This helps the model to capture a shift between the groups without changing how the continuous model affects the outcome.\n",
    "\n",
    "4. The result is two different lines with two different slopes and intercepts, allowing the model to capture how the continuous variable changes across the different categories.\n",
    "\n",
    "5. The model is able to compare each category to the reference category while keeping the slopes and continuous variation out of the equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b408a",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "\n",
    "1. Equation without Interaction: Sales = beta0 + beta1 (TV Spend) + beta2 (Online Spend) + error\n",
    "\n",
    "   Without interaction, each budget type independently affects sales. When making predictions, predicted sales are the sum of the baseline, TV Spend, ad spend, and online spend. These are all treated independently and the model assumes the spend on TV is the same no matter the online spending and vice versa.\n",
    "   \n",
    "   ##### Predicted Sales = beta0 + beta1 (TV Spend) + beta2 (Online Spend)\n",
    "\n",
    "   Equation With Interaction: Sales = beta0 + beta1 (TV Spend) + beta2 (Online Spend) + beta3 (TV Spend x Online Spend) + error\n",
    "   \n",
    "   With Interaction, predicted sales incoporate both invidiual and interaction effect. What this means is that the model accounts for combined effects. \n",
    "   \n",
    "   ##### Predicted Sales = beta0 + beta1 (TV Spend) + beta2 (Online Spend) + beta3 (TV Spend x Online Spend)\n",
    "   \n",
    "      \n",
    "2. High and low sets two binary indicator variables instead of continuous variables, and can be seen as:\n",
    "    \n",
    "   Without Interaction = beta0 + beta1 (TV High) + beta2 (Online High) + error\n",
    "   \n",
    "   With Interaction = beta0 + beta1 (TV High) + beta2 (Online High) + beta3 (TV High x Online High) + error\n",
    "   \n",
    "   Predicted Sales Without Interactions = beta0 + beta1 (TV High) + beta2 (Online High) -> Assumes constistency across budget levels\n",
    "   \n",
    "   Predicted Sales With Interactions = beta0 + beta1 (TV High) + beta2 (Online High) + beta3 (TV High x Online High) -> allows for different predicted sales depending on the levels of each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497ccb3",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbfce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset and identify potential continous, binary, and categorial variables\n",
    "data = pd.read_csv('CSCS_data_anon.csv')\n",
    "# Inspect data\n",
    "data.info()\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd07130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# You can specify models in the form of a formula\n",
    "# Example formula for additive model\n",
    "model_additive = smf.ols('social_connection_score ~ age + income + C(is_employed) + C(marital_status)', data=data).fit()\n",
    "print(model_additive.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d139d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example formula with interaction; introduce interaction terms\n",
    "model_interaction = smf.ols('social_connection_score ~ age * income + C(is_employed) * C(marital_status)', data=data).fit()\n",
    "print(model_interaction.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6dbb8d",
   "metadata": {},
   "source": [
    "With PLOTLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a211688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Scatter plot with best fit line for additive model\n",
    "fig_additive = px.scatter(data, x='age', y='social_connection_score', color='is_employed',\n",
    "                          trendline=\"ols\", trendline_scope=\"overall\")\n",
    "fig_additive.update_layout(title=\"Additive Model: Social Connection Score vs Age by Employment Status\")\n",
    "fig_additive.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d19bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with best fit line for interaction model\n",
    "fig_interaction = px.scatter(data, x='age', y='social_connection_score', color='is_employed',\n",
    "                             trendline=\"ols\", trendline_scope=\"group\")\n",
    "fig_interaction.update_layout(title=\"Interaction Model: Social Connection Score vs Age by Employment Status\")\n",
    "fig_interaction.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ac14d5",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "The statement \"the model only explains 17.6% of the variability in the data\" refers to the value of R squared. It measures how well the model explains in the outcome variable. An R squared of 17.6% means that the model caputres limited variability in the outcome, suggesting limited predictive power. The second statement in the question indicates that several predictors are statistically significant, with p-values small enough to reject the null hypothesis. These large coefficients suggest that some predictors have a huge effect on the outcome despite the limited predicitive power of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063369c4",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "\n",
    "- cell number one is prepared and cleaned the dataset. It does this by removing missing values in the \"Type 2\" column, setting a seed for consistent splits, and splits the dataset into a training and test set\n",
    "- cell number two performs a SLR using the 'statsmodel' library. It models the relationship between a Pokemon's HP and its Attack and Defense stats. The purpose is to predict create a linear and predict HP based on Attack and Defense\n",
    "- cell number three evaluates the performance on both training and test datasets by calculating the in-sample and out-sample of R squared values for the linear regression model \n",
    "- cell number four sets up a MLR and it explores how multiple main effects and their interactions relate to the HP of the pokemon\n",
    "- cell number five uses R^2 values to evaluate the performance of the conplex linear regression on both the training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f76db",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "\n",
    "The 'model_linear_form' forumla creates a complex linear regression model by including both main effects, such as Attack, Defense, Speed, with all possible interactions between these variables. This creates a design matrix, where each column corresponds to a predictor or an interactive term. However, multicollinearity may occur, which is when numerous interactions often result in predictors to become high correlated. This means that the model is sensitive to small changes in the data, and as a result, the model fails to generalize new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71e662",
   "metadata": {},
   "source": [
    "#### Question 7\n",
    "\n",
    "Model 5 has the introduction of a broader set of predictors, extending off of the previous simpler models. Model 6 refines the predictor set by simplifying the formula and focusing on the most significant variables. Model 7 further refines the predictor set with the help of including more complexity and interactions, increasing the predictive power of the model by capturing more detailed relationships. The progressive refining of predictor sets enhance each newer model, improving predictive accuracy while reducing issues such as overfitting and multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb574aa7",
   "metadata": {},
   "source": [
    "#### Question 8\n",
    "\n",
    "Each iteration splits the dataset into a training and testing set using a 50-50 split. To ensure different splits each time, we do the splitting without setting the seed for each loop iteration. Then, the linear regression model is fit on the training data (pokemon_train) using the formula HP ~ Attack + Defense. After the fitting, R^2 is calculated and stored, which represents how well the model fits the training data. The out-of-sample-R^2 is then computed, which represents how well the model generalizes new data. The in-sample and out-of-sample R^2 values for each repitition are collected in arrays named 'in_sample_Rsquared and out_of_sample_Rsqaured, which are then compiled into a DataFrame. Next, using Plotly, a scatter plot is generated to visualize the relationship between the in-sample and out-of-sample R^2 values. A reference line of y = x is added to indicate perfect alignment between in-sample and out-of-sample performance. The points that we find near the line represents models that generalize well, while further away points symbolize overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7928a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize arrays to store R-squared values for each repetition\n",
    "reps = 100\n",
    "in_sample_Rsquared = np.array([0.0]*reps)\n",
    "out_of_sample_Rsquared = np.array([0.0]*reps)\n",
    "\n",
    "# Define the linear form for model3\n",
    "linear_form = 'HP ~ Attack + Defense'\n",
    "\n",
    "# Loop for 100 repetitions\n",
    "for i in range(reps):\n",
    "    # Split the data into training and testing sets (50-50 split)\n",
    "    pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=0.5)\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model3_spec = smf.ols(formula=linear_form, data=pokeaman_train)\n",
    "    model3_fit = model3_spec.fit()\n",
    "    \n",
    "    # Capture the in-sample R-squared value\n",
    "    in_sample_Rsquared[i] = model3_fit.rsquared\n",
    "    \n",
    "    # Capture the out-of-sample R-squared value\n",
    "    yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "    y = pokeaman_test.HP\n",
    "    out_of_sample_Rsquared[i] = np.corrcoef(y, yhat_model3)[0, 1]**2\n",
    "\n",
    "# Collect the performance metrics into a DataFrame for visualization\n",
    "df = pd.DataFrame({\n",
    "    \"In Sample Performance (Rsquared)\": in_sample_Rsquared,\n",
    "    \"Out of Sample Performance (Rsquared)\": out_of_sample_Rsquared\n",
    "})\n",
    "\n",
    "# Create a scatter plot to visualize the relationship between in-sample and out-of-sample performance\n",
    "fig = px.scatter(df, x=\"In Sample Performance (Rsquared)\", \n",
    "                     y=\"Out of Sample Performance (Rsquared)\", \n",
    "                     title=\"In-Sample vs Out-of-Sample Performance\")\n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0,1], name=\"y=x\", line_shape='linear'))\n",
    "\n",
    "# Display the plot\n",
    "fig.show(\"renderer = png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9edd4af",
   "metadata": {},
   "source": [
    "#### Question 9\n",
    "\n",
    "The code works to compare multiple linear regression models using the R^2 value to evaluate how well the in-sample and out-of-sample fit in the data. The first part of the code creates a regression model for data where generation == 1. Then, it calculates the R^2 value on the data. The 'in-sample' R^2 is then calculated using model7_fit.rsquared for the orginal model. Next, the 'out-of-sample' R^2 is calculated by comparing the predictions against the test set 'pokeaman_test.HP'. For each subset of each dataset, this process is repeated, and the performance of each is checked on another to test its generalizatbility. The purpose of this comparison is to check wether the model performs better on the 'in-sample' data compared to how it predicts the 'out-of-sample' data.\n",
    "\n",
    "For the other models, each is assessed using a similar process. This allows you to determine if the model trained on data from Generation 1 can correctly predict from other generations. For some definitions, the in-sample R^2 measures how well the model fits on the data that it was trained on while the out-of-sample R^2 measures how well the model performs on new data that was never seen before. A higher value for both generally means that it does it well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
